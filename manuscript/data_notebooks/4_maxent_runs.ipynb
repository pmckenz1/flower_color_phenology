{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d6a9f4-1c0d-42ae-ae34-b324e08ef993",
   "metadata": {},
   "source": [
    "# Running maxent on the full GPT-labeled data, as well as for pollinators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e927e-4598-457f-b263-0f2769e6c3e3",
   "metadata": {},
   "source": [
    "## README:\n",
    "In this notebook I am using some custom code (derived from my old repo SMOOD: https://github.com/pmckenz1/smood) to easily automate Maxent runs. Unfortunately this notebook is kind of messy, as I re-copied in the modified SMOOD code several times through the notebook to make slight adjustments to the Maxent options, for example to use jackknifing.  \n",
    "\n",
    "In this notebook I make directories that give the distribution on every day of the year for red flowers, white flowers, bumblebees, and hummingbirds. Toward the end of the notebook I infer the distributions of red vs. white flowers with bumblebees and hummingbirds as predictors alongside environmental variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6044a-3afc-46ec-a34b-e151dc98cf5f",
   "metadata": {},
   "source": [
    "### maxent options here: https://groups.google.com/g/maxent/c/yRBlvZ1_9rQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37420000-57fa-4978-8a1e-4ee193d56508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from IPython.display import Image\n",
    "from dateutil import parser\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa4493e1-daad-4e4d-8d63-42371cba0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    str(idx)+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "                                                      self.profile['run_name']+\".asc\"),\n",
    "                                         delimiter=' ',\n",
    "                                         skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f7cc0-f36a-4f6d-a43c-4edaff0a1612",
   "metadata": {},
   "source": [
    "# Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "440c8e5f-079a-4b22-9d35-75d195c65703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qh/c7rwx84921n2kznn09zb2pnh0000gn/T/ipykernel_2175/945864032.py:1: DtypeWarning: Columns (14,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dat = pd.read_csv('../data/fulldata_cleaned_matched_GPT_colors.csv')\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv('../data/fulldata_cleaned_matched_GPT_colors.csv')\n",
    "red_validated = pd.read_csv('../data/validated_FULL_gpt_labeled_REDS_ONLY.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6b4a9-7840-4c67-85dd-8fe1e6683f16",
   "metadata": {},
   "source": [
    "### Screen out all of the GPT-labeled reds that aren't truly red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b63202a5-5769-427a-8d9c-849014477074",
   "metadata": {},
   "outputs": [],
   "source": [
    "for binom in red_validated.binomial[red_validated.validated.eq('no')]:\n",
    "    dat = dat[dat.binomial != binom]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7affb90b-556a-49a1-a6c6-fb652d7b5496",
   "metadata": {},
   "source": [
    "## Red flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99504e1c-befb-456e-96ce-2bfbcb4c07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "reds = ['red']\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(reds)]\n",
    "    mapper = Mapper(subdf,run_name='red'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/red_flowers/',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1,2,3,4,5,6,7,10,11,12,13,14,15,16,17,18,19]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd81915-6c6d-45d4-b179-dc25e4bdee8a",
   "metadata": {},
   "source": [
    "## White flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289f66b-5769-445e-8c3a-0f051b03d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the whites\n",
    "colors = ['white']\n",
    "run_name_prefix = 'white'\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = inatdata_plus_color[inatdata_plus_color.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(colors)]\n",
    "    mapper = Mapper(subdf,run_name=run_name_prefix+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='./data/maxent/outputs',\n",
    "       maxent_path='./bins/maxent.jar',\n",
    "       worldclim_dir='./data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1,2,3,4,5,6,7,10,11,12,13,14,15,16,17,18,19]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb18824-87c9-4a41-9b06-9e25a75ab66c",
   "metadata": {},
   "source": [
    "# Now do a linear version of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b9d8b71-5a6f-4b45-8098-4c3163b3ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            ascname = filepath.split(os.sep)[-1] # take just the name\n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    ascname+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "                                                      self.profile['run_name']+\".asc\"),\n",
    "                                         delimiter=' ',\n",
    "                                         skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} quadratic=false product=false threshold=false hinge=false redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e74051-d367-4c0f-9671-84ff59f5c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "reds = ['red']\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(reds)]\n",
    "    mapper = Mapper(subdf,run_name='red'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/red_flowers_linear/',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1,2,3,4,5,6,7,10,11,12,13,14,15,16,17,18,19]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e457d7-fb64-49e7-9dd0-be7b66934b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "colors = ['white']\n",
    "run_name_prefix = 'white'\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(colors)]\n",
    "    mapper = Mapper(subdf,run_name=run_name_prefix+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/white_flowers_linear',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1,2,3,4,5,6,7,10,11,12,13,14,15,16,17,18,19]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451429f-fe54-4ba5-8f21-35a40d6b6dae",
   "metadata": {},
   "source": [
    "## With jackknifing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f7ee771e-c660-42b3-9691-621b552520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "            20: os.path.join(self.worldclim_dir, \"wc2.1_10m_elev.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            ascname = filepath.split(os.sep)[-1] # take just the name\n",
    "            \n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    ascname+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "                                                      self.profile['run_name']+\".asc\"),\n",
    "                                         delimiter=' ',\n",
    "                                         skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} quadratic=false product=false threshold=false hinge=false jackknife=false randomtestpoints=20 redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "912446d8-14fa-4711-8b60-07656760940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "reds = ['red']\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(reds)]\n",
    "    mapper = Mapper(subdf,run_name='red'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/red_flowers_linear/',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          5, # Max Temperature of Warmest Month\n",
    "                          6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          12, # Annual Precipitation\n",
    "                          13, # Precipitation of Wettest Month\n",
    "                          14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bce8ef-ad3d-4cb6-ae03-22f79e75c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the whites\n",
    "colors = ['white']\n",
    "run_name_prefix = 'white'\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(colors)]\n",
    "    mapper = Mapper(subdf,run_name=run_name_prefix+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/white_flowers_linear',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          5, # Max Temperature of Warmest Month\n",
    "                          6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          12, # Annual Precipitation\n",
    "                          13, # Precipitation of Wettest Month\n",
    "                          14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e882a97-693e-43bb-8176-da64686e21d7",
   "metadata": {},
   "source": [
    "# Trochilidae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad1457f7-f1b5-4b67-905c-64045fbdaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "troch_dat = pd.read_csv('../raw_inaturalist_exports/hummingbirds/observations-395877.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fa0f4a5-da43-4656-9153-7e8721b83613",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_list = []\n",
    "for date in troch_dat.observed_on:\n",
    "    dt = parser.parse(date)\n",
    "    day_of_year = dt.timetuple().tm_yday\n",
    "    days_list.append(day_of_year)\n",
    "    \n",
    "troch_dat['day_of_year'] = days_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69734105-8391-442f-a0c8-4e605283d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "            20: os.path.join(self.worldclim_dir, \"wc2.1_10m_elev.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            ascname = filepath.split(os.sep)[-1] # take just the name\n",
    "            \n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    ascname+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "                                                      self.profile['run_name']+\".asc\"),\n",
    "                                         delimiter=' ',\n",
    "                                         skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} quadratic=false product=false threshold=false hinge=false jackknife=false redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a50a9cd4-2f38-41e1-830b-fadd952d0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Sample at -78.4485895247, 26.8360013461 in hummingbird_0.csv is missing some environmental data (e.g. wc2.0_bio_10m_01.tif)\n",
      "Warning: Skipping sample at -78.4485895247, 26.8360013461 which has no environmental data\n"
     ]
    }
   ],
   "source": [
    "# do all of the hummingbirds\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = troch_dat[troch_dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    mapper = Mapper(subdf,run_name='hummingbird'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/hummingbirds/',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          5, # Max Temperature of Warmest Month\n",
    "                          6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          12, # Annual Precipitation\n",
    "                          13, # Precipitation of Wettest Month\n",
    "                          14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6eb6a-78f5-4f19-b551-34129976968b",
   "metadata": {},
   "source": [
    "# Bombus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adf48c4e-2f28-4a5f-a442-6b1e87b332f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where the input files are stored\n",
    "raw_obs_directory = '../raw_inaturalist_exports/bumblebees/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0cfead2-d1cf-4ad4-a253-69ec073a2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file names (as downloaded from inaturalist)\n",
    "filenames = ['observations-396610.csv.zip',\n",
    " 'observations-396616.csv.zip',\n",
    " 'observations-396678.csv.zip',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "369655f0-c3aa-4d5a-acb3-e44c471b57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the full file paths\n",
    "file_paths = [os.path.join(raw_obs_directory,i) for i in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13e2399e-ed13-401d-8c6b-330eab451b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the concatenated data\n",
    "bombus_dat = pd.DataFrame()\n",
    "\n",
    "# Loop through file paths and read each file, then concatenate them into all_data\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path,low_memory=False)\n",
    "        \n",
    "        # Concatenate the DataFrame from the file with the main DataFrame\n",
    "        bombus_dat = pd.concat([bombus_dat, df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"No data in file: {file_path}\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error parsing data from file: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62f918dc-bcfb-4ff1-b9cf-d46bc3348f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_list = []\n",
    "for date in bombus_dat.observed_on:\n",
    "    dt = parser.parse(date)\n",
    "    day_of_year = dt.timetuple().tm_yday\n",
    "    days_list.append(day_of_year)\n",
    "    \n",
    "bombus_dat['day_of_year'] = days_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036174ab-f5af-4505-812f-87da199536ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all bombus\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = bombus_dat[bombus_dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    mapper = Mapper(subdf,run_name='bombus'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir='../data/maxent/jan24outputs/bumblebees/',\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          5, # Max Temperature of Warmest Month\n",
    "                          6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          12, # Annual Precipitation\n",
    "                          13, # Precipitation of Wettest Month\n",
    "                          14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db015a8-eb9a-43cf-aa75-df01c9f629b1",
   "metadata": {},
   "source": [
    "# Using just the two predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f4e91-2194-4268-ad4e-9ced73ae3134",
   "metadata": {},
   "source": [
    "### Make sure to turn on jackknifing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d29044c-6682-402f-ae65-15ebc1d7fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "            20: os.path.join(self.worldclim_dir, \"wc2.1_10m_elev.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "        else:\n",
    "            self.profile['worldclim_layers'] = []\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            ascname = filepath.split(os.sep)[-1] # take just the name\n",
    "            \n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    ascname+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "                                                      self.profile['run_name']+\".asc\"),\n",
    "                                         delimiter=' ',\n",
    "                                         skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} quadratic=false product=false threshold=false hinge=false jackknife=true randomtestpoints=20 redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "817d6eea-a8aa-4097-95f3-11d47dd6f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "reds = ['red']\n",
    "bombus_maxent_dir = '../data/maxent/jan24outputs/bumblebees/'\n",
    "troch_maxent_dir = '../data/maxent/jan24outputs/hummingbirds/'\n",
    "outputs_dir = '../data/maxent/jan24outputs/red_flowers_troch_bombus/'\n",
    "envfile_dir = os.path.join(outputs_dir,'envfiles')\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(reds)]\n",
    "    \n",
    "    # copy the proper envfiles to the envfiles folder\n",
    "    \n",
    "    # Specify the BOMBUS source file path\n",
    "    source_file_path = os.path.join(bombus_maxent_dir,'bombus_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    # Specify the TROCH source file path\n",
    "    source_file_path = os.path.join(troch_maxent_dir,'hummingbird_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    mapper = Mapper(subdf,run_name='red'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir=outputs_dir,\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[#1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          #5, # Max Temperature of Warmest Month\n",
    "                          #6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          #12, # Annual Precipitation\n",
    "                          #13, # Precipitation of Wettest Month\n",
    "                          #14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          #20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()\n",
    "    \n",
    "    # delete the envfiles for this start day\n",
    "    for filename in os.listdir(envfile_dir):\n",
    "        file_path = os.path.join(envfile_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a4ae2-a9f5-4a86-8894-5f64e4ce22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the whites\n",
    "colors = ['white']\n",
    "run_name_prefix = 'white'\n",
    "\n",
    "bombus_maxent_dir = '../data/maxent/jan24outputs/bumblebees/'\n",
    "troch_maxent_dir = '../data/maxent/jan24outputs/hummingbirds/'\n",
    "outputs_dir = '../data/maxent/jan24outputs/white_flowers_troch_bombus/'\n",
    "envfile_dir = os.path.join(outputs_dir,'envfiles')\n",
    "\n",
    "\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(colors)]\n",
    "    \n",
    "    # copy the proper envfiles to the envfiles folder\n",
    "    \n",
    "    # Specify the BOMBUS source file path\n",
    "    source_file_path = os.path.join(bombus_maxent_dir,'bombus_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    # Specify the TROCH source file path\n",
    "    source_file_path = os.path.join(troch_maxent_dir,'hummingbird_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    mapper = Mapper(subdf,run_name=run_name_prefix+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir=outputs_dir,\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[#1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          #5, # Max Temperature of Warmest Month\n",
    "                          #6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          #12, # Annual Precipitation\n",
    "                          #13, # Precipitation of Wettest Month\n",
    "                          #14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          #20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()\n",
    "    \n",
    "    # delete the envfiles for this start day\n",
    "    for filename in os.listdir(envfile_dir):\n",
    "        file_path = os.path.join(envfile_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ed3ae-4ab7-4e90-b1b8-c604a5cce677",
   "metadata": {},
   "source": [
    "# With replicates, using bombus and hummingbird maps as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51cdac62-4579-4098-9f4a-fa986fdb0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "            20: os.path.join(self.worldclim_dir, \"wc2.1_10m_elev.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "        else:\n",
    "            self.profile['worldclim_layers'] = []\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            ascname = filepath.split(os.sep)[-1] # take just the name\n",
    "            \n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    ascname+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        #self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "        #                                              self.profile['run_name']+\".asc\"),\n",
    "        #                                 delimiter=' ',\n",
    "        #                                 skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        #self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} quadratic=false product=false threshold=false hinge=false jackknife=true randomtestpoints=20 outputgrids=false replicates=10 replicatetype=crossvalidate redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd56a8-9a10-4faf-bc34-7ee6bb94eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "reds = ['red']\n",
    "bombus_maxent_dir = '../data/maxent/jan24outputs/bumblebees/'\n",
    "troch_maxent_dir = '../data/maxent/jan24outputs/hummingbirds/'\n",
    "outputs_dir = '../data/maxent/jan24outputs/red_flowers_troch_bombus_10CV/'\n",
    "envfile_dir = os.path.join(outputs_dir,'envfiles')\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(reds)]\n",
    "    \n",
    "    # copy the proper envfiles to the envfiles folder\n",
    "    \n",
    "    # Specify the BOMBUS source file path\n",
    "    source_file_path = os.path.join(bombus_maxent_dir,'bombus_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    # Specify the TROCH source file path\n",
    "    source_file_path = os.path.join(troch_maxent_dir,'hummingbird_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    mapper = Mapper(subdf,run_name='red'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir=outputs_dir,\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[#1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          #5, # Max Temperature of Warmest Month\n",
    "                          #6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          #12, # Annual Precipitation\n",
    "                          #13, # Precipitation of Wettest Month\n",
    "                          #14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          #20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()\n",
    "    \n",
    "    # delete the envfiles for this start day\n",
    "    for filename in os.listdir(envfile_dir):\n",
    "        file_path = os.path.join(envfile_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82a04e-c41b-478c-a14b-5eeeaab1ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the whites\n",
    "colors = ['white']\n",
    "run_name_prefix = 'white'\n",
    "\n",
    "bombus_maxent_dir = '../data/maxent/jan24outputs/bumblebees/'\n",
    "troch_maxent_dir = '../data/maxent/jan24outputs/hummingbirds/'\n",
    "outputs_dir = '../data/maxent/jan24outputs/white_flowers_troch_bombus_10CV/'\n",
    "envfile_dir = os.path.join(outputs_dir,'envfiles')\n",
    "\n",
    "\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(colors)]\n",
    "    \n",
    "    # copy the proper envfiles to the envfiles folder\n",
    "    \n",
    "    # Specify the BOMBUS source file path\n",
    "    source_file_path = os.path.join(bombus_maxent_dir,'bombus_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    # Specify the TROCH source file path\n",
    "    source_file_path = os.path.join(troch_maxent_dir,'hummingbird_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    mapper = Mapper(subdf,run_name=run_name_prefix+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir=outputs_dir,\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[#1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          #5, # Max Temperature of Warmest Month\n",
    "                          #6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          #12, # Annual Precipitation\n",
    "                          #13, # Precipitation of Wettest Month\n",
    "                          #14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          #20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()\n",
    "    \n",
    "    # delete the envfiles for this start day\n",
    "    for filename in os.listdir(envfile_dir):\n",
    "        file_path = os.path.join(envfile_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34879e04-f8df-4d22-88c3-1207ae1c15f7",
   "metadata": {},
   "source": [
    "# Without replicates, including environmental layers and pollinators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e56c4ad8-905c-47df-96cb-386f8c0ecd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapper:\n",
    "    \"\"\"\n",
    "    The object central to `smood` (simple mapping of occurrence data).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        run_name=\"test\",\n",
    "        lat_range=None,\n",
    "        lon_range=None,\n",
    "        worldclim_layers=list(range(1, 20)),\n",
    "        outputs_dir=\"maxent_outputs/\",\n",
    "        write_outputs=False,\n",
    "        maxent_path=None,\n",
    "        worldclim_dir=None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        The object central to `smood` (simple mapping of occurrence data).\n",
    "        Users supply a species name, latitude range, and longitude range, and\n",
    "        then they can run automated maxent sdms over this.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        species_name (str):\n",
    "            The name of the species.\n",
    "            e.g., \"Monarda fistulosa\"\n",
    "        lat_range (list, tuple):\n",
    "            A list of the latitude values, low and high, used as bounds for the map.\n",
    "            e.g., (30, 50)\n",
    "            Values must be from the range [-90,90]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        lon_range (list, tuple):\n",
    "            A list of the longitude values, low and high, used as bounds for the map.\n",
    "            e.g., (-100, -50)\n",
    "            Values must be from the range [-180,180]\n",
    "            These values are sorted later on, so the order doesn't matter.\n",
    "        worldclim_layers (list):\n",
    "            A list of the layers to use from worldclim. By default, this list contains\n",
    "            integers 1 through 19, corresponding to all 19 worldclime layers.\n",
    "        \"\"\"\n",
    "\n",
    "        self.profile = {}\n",
    "\n",
    "        self.df = df\n",
    "        \n",
    "        self.profile['run_name'] = run_name\n",
    "        if lat_range:\n",
    "            _ = np.sort(lat_range)\n",
    "            self.profile['ymin'] = _[0]\n",
    "            self.profile['ymax'] = _[1]\n",
    "        else:\n",
    "            self.profile['ymin'] = None\n",
    "            self.profile['ymax'] = None\n",
    "\n",
    "        if lon_range:\n",
    "            _ = np.sort(lon_range)\n",
    "            self.profile['xmin'] = _[0]\n",
    "            self.profile['xmax'] = _[1]\n",
    "        else:\n",
    "            self.profile['xmin'] = None\n",
    "            self.profile['xmax'] = None\n",
    "\n",
    "        if not maxent_path:\n",
    "            # make the maxent path give the path to the .jar in the package directory...\n",
    "            self.maxent_path = os.path.join(self.upper_package_level,\n",
    "                                            'bins',\n",
    "                                            'maxent.jar')\n",
    "        else:\n",
    "            self.maxent_path = maxent_path\n",
    "\n",
    "        if not worldclim_dir:\n",
    "            self.worldclim_dir = os.path.join(self.upper_package_level,\n",
    "                                              'worldclim')\n",
    "        else:\n",
    "            self.worldclim_dir = worldclim_dir\n",
    "\n",
    "        self.worldclim_dict = {\n",
    "            1:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_01.tif\"),\n",
    "            2:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_02.tif\"),\n",
    "            3:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_03.tif\"),\n",
    "            4:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_04.tif\"),\n",
    "            5:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_05.tif\"),\n",
    "            6:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_06.tif\"),\n",
    "            7:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_07.tif\"),\n",
    "            8:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_08.tif\"),\n",
    "            9:  os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_09.tif\"),\n",
    "            10: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_10.tif\"),\n",
    "            11: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_11.tif\"),\n",
    "            12: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_12.tif\"),\n",
    "            13: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_13.tif\"),\n",
    "            14: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_14.tif\"),\n",
    "            15: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_15.tif\"),\n",
    "            16: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_16.tif\"),\n",
    "            17: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_17.tif\"),\n",
    "            18: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_18.tif\"),\n",
    "            19: os.path.join(self.worldclim_dir, \"wc2.0_bio_10m_19.tif\"),\n",
    "            20: os.path.join(self.worldclim_dir, \"wc2.1_10m_elev.tif\"),\n",
    "        }\n",
    "\n",
    "        if worldclim_layers:\n",
    "            self.profile['worldclim_layers'] = worldclim_layers\n",
    "        else:\n",
    "            self.profile['worldclim_layers'] = []\n",
    "\n",
    "        # name folder for maxent outputs\n",
    "        self.outputs_dir = outputs_dir\n",
    "\n",
    "        # name folder for clipped/converted worldclim\n",
    "        #self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "        #                                 \"envfiles\")\n",
    "        self.envfiles_dir = os.path.join(self.outputs_dir,\n",
    "                                         \"envfiles\")\n",
    "\n",
    "        self.key = None\n",
    "        self.write_outputs = write_outputs\n",
    "\n",
    "    def _get_gbif_occs(self):\n",
    "        # get the gbif key for our species\n",
    "        self.occfile = os.path.join(self.outputs_dir,\n",
    "                                    self.profile['run_name']+\".csv\")\n",
    "\n",
    "        # make lists to fill\n",
    "        self.lats = list(self.df.latitude)\n",
    "        self.lons = list(self.df.longitude)\n",
    "\n",
    "        # prepare array to write to csv\n",
    "        csvarr = np.vstack([np.repeat(self.profile['run_name'], len(self.lons)),\n",
    "                            self.lons,\n",
    "                            [\"{}{}\".format(a_, b_) for a_, b_ in zip(self.lats, \n",
    "                                                                     np.repeat('\\n', \n",
    "                                                                               len(self.lats)\n",
    "                                                                               )\n",
    "                                                                     )\n",
    "                             ]\n",
    "                            ]).T\n",
    "        # write occurrence data to csv\n",
    "        with open(self.occfile, 'w') as f:\n",
    "            f.write('Species,Longitude,Latitude\\n')\n",
    "            for line in csvarr:\n",
    "                f.write(\",\".join(line))\n",
    "\n",
    "        # make these easier to work with downstream\n",
    "        self.lons = np.array(self.lons)\n",
    "        self.lats = np.array(self.lats)\n",
    "\n",
    "    def _write_env_rasters(self):\n",
    "        \"\"\"\n",
    "        Looks at raw worldclim data, clips it to specified bounding box, and writes the result as ascii.\n",
    "        \"\"\"\n",
    "        # loop through the worldclim master files\n",
    "        for idx, filepath in enumerate([self.worldclim_dict[layer_int] for layer_int in self.profile['worldclim_layers']]):\n",
    "            # open with rasterio\n",
    "            envdata = rasterio.open(filepath, 'r')\n",
    "\n",
    "            # define a window using lat and lon\n",
    "            win1 = envdata.window(self.profile['xmin'],\n",
    "                                  self.profile['ymin'],\n",
    "                                  self.profile['xmax'],\n",
    "                                  self.profile['ymax'])\n",
    "\n",
    "            # read env data from the window\n",
    "            windowarr = envdata.read(window=win1)[0]\n",
    "\n",
    "            # get affine transform (this will be used to get cell size)\n",
    "            aff = envdata.profile['transform']\n",
    "\n",
    "            # get number of columns in the window\n",
    "            ncols = windowarr.shape[1]\n",
    "\n",
    "            # get number of rows in the window\n",
    "            nrows = windowarr.shape[0]\n",
    "\n",
    "            # define the lower left corner x coordinate (in degrees)\n",
    "            xllcorner = self.profile['xmin']\n",
    "\n",
    "            # define the lower left corner y coordinate (in degrees)\n",
    "            yllcorner = self.profile['ymin']\n",
    "\n",
    "            # save the cell size from the affine transform\n",
    "            cellsize = aff.a\n",
    "\n",
    "            # record the value corresponding to nodata\n",
    "            nodata_value = envdata.profile['nodata']\n",
    "\n",
    "            # save ascii file -- saving array with space delimiter, and metadata as a header\n",
    "            ascname = filepath.split(os.sep)[-1] # take just the name\n",
    "            \n",
    "            np.savetxt(os.path.join(self.envfiles_dir,\n",
    "                                    ascname+'.asc'),\n",
    "                       windowarr,\n",
    "                       delimiter=' ',\n",
    "                       comments='',\n",
    "                       header=\"\".join(['ncols {}\\n'.format(ncols),\n",
    "                                       'nrows {}\\n'.format(nrows),\n",
    "                                       'xllcorner {}\\n'.format(xllcorner),\n",
    "                                       'yllcorner {}\\n'.format(yllcorner),\n",
    "                                       'cellsize {}\\n'.format(cellsize),\n",
    "                                       'nodata_value {}'.format(nodata_value)]))\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs gbif and maxent on the species name and bounds provided.\n",
    "        \"\"\"\n",
    "\n",
    "        # make these directories\n",
    "        #os.mkdir(self.outputs_dir)\n",
    "        #os.mkdir(self.envfiles_dir)\n",
    "\n",
    "        self._get_gbif_occs()\n",
    "        self._write_env_rasters()\n",
    "\n",
    "        # run maxent from command line\n",
    "\n",
    "        mkseq = Maxent(self.maxent_path)\n",
    "        mkseq.open_subprocess()\n",
    "        mkseq.feed_maxent(self.envfiles_dir,\n",
    "                          self.occfile,\n",
    "                          self.outputs_dir,\n",
    "                          )\n",
    "        mkseq.close_subprocess()\n",
    "\n",
    "        # save png output from maxent\n",
    "        self.maxent_image = Image(os.path.join(self.outputs_dir,\n",
    "                                               \"plots\",\n",
    "                                               self.profile['run_name']+\".png\"))\n",
    "\n",
    "        # save raster output from maxent\n",
    "        #self.density_mat = np.genfromtxt(os.path.join(self.outputs_dir,\n",
    "        #                                              self.profile['run_name']+\".asc\"),\n",
    "        #                                 delimiter=' ',\n",
    "        #                                 skip_header=6)\n",
    "        # remove the nans (maxent saves these as -9999)\n",
    "        #self.density_mat[self.density_mat == -9999] = np.nan\n",
    "\n",
    "        # remove the outputs, we have what we need in memory\n",
    "        if not self.write_outputs:\n",
    "            rmtree(self.outputs_dir)\n",
    "            \n",
    "import os\n",
    "import subprocess as sps\n",
    "\n",
    "\n",
    "class Maxent:\n",
    "    \"\"\"\n",
    "    Opens a view to seq-gen in a subprocess so that many gene trees can be\n",
    "    cycled through without the overhead of opening/closing subprocesses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxent_path):\n",
    "\n",
    "        # set binary path for conda env and check for binary\n",
    "        self.binary = maxent_path\n",
    "        assert os.path.exists(self.binary), (\n",
    "            \"binary {} not found\".format(self.binary))\n",
    "\n",
    "        # call open_subprocess to set the shell\n",
    "        self.shell = None\n",
    "\n",
    "    def open_subprocess(self):\n",
    "        \"\"\"\n",
    "        Open a persistent Popen bash shell\n",
    "        \"\"\"\n",
    "        # open\n",
    "        self.shell = sps.Popen(\n",
    "            [\"bash\"], stdin=sps.PIPE, stdout=sps.PIPE, bufsize=0)\n",
    "\n",
    "    def close_subprocess(self):\n",
    "        \"\"\"\n",
    "        Cleanup and shutdown the subprocess shell.\n",
    "        \"\"\"\n",
    "        self.shell.stdin.close()\n",
    "        self.shell.terminate()\n",
    "        self.shell.wait(timeout=1.0)\n",
    "\n",
    "    def feed_maxent(self, envfiles_dir, occfile, outputs_dir):\n",
    "        \"\"\"\n",
    "        Feed a command string a read results until empty line.\n",
    "        TODO: allow kwargs to add additional seq-gen args.\n",
    "        \"\"\"\n",
    "        # command string\n",
    "        cmd = (\n",
    "            \"java -mx512m -jar {} nowarnings environmentallayers={} samplesfile={} outputdirectory={} quadratic=false product=false threshold=false hinge=false jackknife=true randomtestpoints=20 redoifexists autorun; echo done\\n\"\n",
    "            .format(self.binary, envfiles_dir, occfile, outputs_dir)\n",
    "        )\n",
    "\n",
    "        # feed to the shell\n",
    "        self.shell.stdin.write(cmd.encode())\n",
    "        self.shell.stdin.flush()\n",
    "\n",
    "        # catch returned results until done\\n\n",
    "        hold = []\n",
    "        for line in iter(self.shell.stdout.readline, b\"done\\n\"):\n",
    "            hold.append(line.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c60da-425a-441a-927a-d5deecb7461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the whites\n",
    "colors = ['white']\n",
    "run_name_prefix = 'white'\n",
    "\n",
    "bombus_maxent_dir = '../data/maxent/jan24outputs/bumblebees/'\n",
    "troch_maxent_dir = '../data/maxent/jan24outputs/hummingbirds/'\n",
    "outputs_dir = '../data/maxent/jan24outputs/white_flowers_troch_bombus_environ/'\n",
    "envfile_dir = os.path.join(outputs_dir,'envfiles')\n",
    "\n",
    "\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(colors)]\n",
    "    \n",
    "    # copy the proper envfiles to the envfiles folder\n",
    "    \n",
    "    # Specify the BOMBUS source file path\n",
    "    source_file_path = os.path.join(bombus_maxent_dir,'bombus_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    # Specify the TROCH source file path\n",
    "    source_file_path = os.path.join(troch_maxent_dir,'hummingbird_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    mapper = Mapper(subdf,run_name=run_name_prefix+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir=outputs_dir,\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          5, # Max Temperature of Warmest Month\n",
    "                          6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          12, # Annual Precipitation\n",
    "                          13, # Precipitation of Wettest Month\n",
    "                          14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()\n",
    "    \n",
    "    # delete the envfiles for this start day\n",
    "    for filename in os.listdir(envfile_dir):\n",
    "        file_path = os.path.join(envfile_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cf8b8096-3b83-4582-ba36-5823edebb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all of the reds\n",
    "reds = ['red']\n",
    "bombus_maxent_dir = '../data/maxent/jan24outputs/bumblebees/'\n",
    "troch_maxent_dir = '../data/maxent/jan24outputs/hummingbirds/'\n",
    "outputs_dir = '../data/maxent/jan24outputs/red_flowers_troch_bombus_environ/'\n",
    "envfile_dir = os.path.join(outputs_dir,'envfiles')\n",
    "for start_day in range(0,351,1):\n",
    "    subdf = dat[dat.day_of_year.isin(range(start_day,start_day+15))]\n",
    "    subdf = subdf[subdf.color.isin(reds)]\n",
    "    \n",
    "    # copy the proper envfiles to the envfiles folder\n",
    "    \n",
    "    # Specify the BOMBUS source file path\n",
    "    source_file_path = os.path.join(bombus_maxent_dir,'bombus_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    # Specify the TROCH source file path\n",
    "    source_file_path = os.path.join(troch_maxent_dir,'hummingbird_'+str(start_day)+'.asc')\n",
    "    # Use shutil.copy() to copy the file\n",
    "    shutil.copy(source_file_path, envfile_dir)\n",
    "    \n",
    "    mapper = Mapper(subdf,run_name='red'+'_'+str(start_day),lat_range=[24,54],lon_range=[-130,-59],\n",
    "       outputs_dir=outputs_dir,\n",
    "       maxent_path='../bins/maxent.jar',\n",
    "       worldclim_dir='../data/worldclim/',write_outputs=True,\n",
    "        worldclim_layers=[1, # Annual Mean Temperature\n",
    "                          #2, # Mean Diurnal Range (Mean of monthly (max temp - min temp))\n",
    "                          #3, # Isothermality (BIO2/BIO7) (×100)\n",
    "                          #4, # Temperature Seasonality (standard deviation ×100)\n",
    "                          5, # Max Temperature of Warmest Month\n",
    "                          6, # Min Temperature of Coldest Month\n",
    "                          #7, # Temperature Annual Range (BIO5-BIO6)\n",
    "                          #8, # Mean Temperature of Wettest Quarter\n",
    "                          #9, # Mean Temperature of Driest Quarter\n",
    "                          #10, # Mean Temperature of Warmest Quarter\n",
    "                          #11, # Mean Temperature of Coldest Quarter\n",
    "                          12, # Annual Precipitation\n",
    "                          13, # Precipitation of Wettest Month\n",
    "                          14, # Precipitation of Driest Month\n",
    "                          #15, # Precipitation Seasonality (Coefficient of Variation)\n",
    "                          #16, # Precipitation of Wettest Quarter\n",
    "                          #17, # Precipitation of Driest Quarter\n",
    "                          #18, # Precipitation of Warmest Quarter\n",
    "                          #19, # Precipitation of Coldest Quarter\n",
    "                          20 # NEW elevation (wc 2.1) (from SRTM)\n",
    "                         ]\n",
    "      )\n",
    "    mapper.run()\n",
    "    \n",
    "    # delete the envfiles for this start day\n",
    "    for filename in os.listdir(envfile_dir):\n",
    "        file_path = os.path.join(envfile_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
